# Baseline Model Training Configuration

# MLflow settings
mlflow_tracking_uri: "http://localhost:5000"
experiment_name: "predictive_maintenance_baseline"

# General settings
random_state: 42
use_hyperparameter_tuning: true
tuning_cv_folds: 3

# Model configurations
models:
  logistic_regression:
    enabled: true
    params:
      max_iter: 1000
      class_weight: "balanced"
    param_grid:
      C: [0.01, 0.1, 1.0, 10.0]
      penalty: ["l1", "l2"]
      solver: ["liblinear"]

  random_forest:
    enabled: true
    params:
      class_weight: "balanced"
      n_jobs: -1
    param_grid:
      n_estimators: [100, 200, 300]
      max_depth: [10, 20, null]
      min_samples_split: [2, 5, 10]
      min_samples_leaf: [1, 2, 4]

  gradient_boosting:
    enabled: false  # Disabled by default (slower than XGBoost)
    params:
      learning_rate: 0.1
    param_grid:
      n_estimators: [100, 200]
      max_depth: [3, 5, 7]
      learning_rate: [0.01, 0.1]

  xgboost:
    enabled: true
    params:
      use_label_encoder: false
      eval_metric: "logloss"
    param_grid:
      n_estimators: [100, 200, 300]
      max_depth: [3, 5, 7]
      learning_rate: [0.01, 0.1, 0.3]
      scale_pos_weight: [1, 5, 10]  # For class imbalance
      subsample: [0.8, 1.0]
      colsample_bytree: [0.8, 1.0]

  lightgbm:
    enabled: false  # Disabled by default
    params:
      class_weight: "balanced"
      verbosity: -1
    param_grid:
      n_estimators: [100, 200]
      max_depth: [5, 10, -1]
      learning_rate: [0.01, 0.1]
      num_leaves: [31, 63]
