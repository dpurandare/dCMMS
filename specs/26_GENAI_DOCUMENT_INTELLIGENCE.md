# Specification: GenAI Document Intelligence (Version 1.0)

**Feature ID:** DCMMS-26-GENAI-DOCS
**Status:** DRAFT
**Priority:** P2 (Release 2/3 Strategic)
**Owner:** AI/ML Team

## 1. Overview
This specification details the architecture for the "GenAI Document Intelligence" feature. The goal is to allow field technicians and operators to query a knowledge base consisting of technical manuals, standard operating procedures (SOPs), historic work orders, and safety contracts using natural language.

## 2. Architecture: RAG (Retrieval-Augmented Generation)

We will utilize a RAG architecture to ensure answers are grounded in our specific private data, minimizing hallucinations.

### 2.1 High-Level Flow
1.  **Ingestion:** Documents (PDF, MD, DOCX) -> Chunker -> Embedding Model -> Vector Database.
2.  **Retrieval:** User Query -> Embedding Model -> Vector DB Similarity Search -> Top-K Contexts.
3.  **Generation:** System Prompt + Contexts + User Query -> LLM -> Answer.

### 2.2 Technology Stack
*   **Vector Database:** `pgvector` extension for PostgreSQL.
    *   *Rationale:* Keeps infrastructure simple by reusing the existing primary DB.
*   **Embedding Model:** `text-embedding-3-small` (OpenAI) or `bge-m3` (Local/Self-hosted).
*   **LLM:** `GPT-4o` (Cloud) or `Llama 3 8B` (Self-hosted via vLLM/Ollama for air-gapped deployments).
*   **Orchestration:** LangChain or LlamaIndex (TypeScript/Python).

## 3. Data Ingestion Pipeline

### 3.1 Supported Document Types
*   **Technical Manuals:** PDF, large text heavy, often poorly formatted. Use `Unstructured.io` or `PyMuPDF` for parsing.
*   **Work Orders:** Historic text data from the `work_orders` table.
*   **Contracts/SOPs:** Markdown or Word documents.

### 3.2 Chunking Strategy
*   **Recursive Character Splitter:** Chunk size ~512-1024 tokens with 10% overlap to maintain context across boundaries.
*   **Metadata Extraction:** Extract `Asset Model`, `Year`, `Error Codes` from text to store as metadata filters.

### 3.3 Database Schema (pgvector)
```sql
CREATE EXTENSION IF NOT EXISTS vector;

CREATE TABLE document_embeddings (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    content TEXT NOT NULL,
    metadata JSONB, -- store source_file, page_number, asset_id
    embedding vector(1536) -- dimensions depend on model
);

CREATE INDEX ON document_embeddings USING hnsw (embedding vector_cosine_ops);
```

## 4. API Specification

### 4.1 Query Endpoint
`POST /api/v1/genai/query`
**Request:**
```json
{
  "query": "How do I reset the inverter error 503?",
  "filters": {
    "assetbox": "SolarEdge",
    "doc_type": "manual"
  }
}
```
**Response:**
```json
{
  "answer": "To reset error 503 on a SolarEdge inverter: 1. Turn the disconnect switch to OFF... [Answer generated by LLM]",
  "citations": [
    { "source": "SolarEdge_Manual_v3.pdf", "page": 42, "score": 0.89 }
  ]
}
```

### 4.2 Ingestion Endpoint (Admin Only)
`POST /api/v1/genai/ingest`
**Request:** Multipart form data (File upload) or S3 Reference.

## 5. Security & Governance
*   **RBAC:** Users can only query documents they are authorized to view.
    *   *Implementation:* Append filter conditions to the vector search (e.g., `WHERE metadata->>'siteId' IN (...)`).
*   **Privacy:** No PII should be fed into public LLMs. Use data masking middleware or self-hosted models for PII-sensitive documents.
*   **Traceability:** Log every Q&A pair with user ID and feedback rating (Thumbs Up/Down) for RLHF or fine-tuning.

## 6. Development Milestones
1.  **Spike:** Setup `pgvector` and ingest 5 manuals. Test retrieval quality.
2.  **Prototype:** Build Chat UI in React. Connect to OpenAI API.
3.  **Production:** Implement Background Job queue (BullMQ) for document processing.
4.  **Optimization:** Implement Hybrid Search (Keyword + Semantic) for better accuracy on exact part numbers.
